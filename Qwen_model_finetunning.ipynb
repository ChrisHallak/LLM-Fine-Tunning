{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ChrisHallak/LLM-Fine-Tunning/blob/main/Qwen_model_finetunning.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Cwy4-_EKFtgB",
        "outputId": "c93f2f07-d25b-4363-e533-74bd292cdd95"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /gdrive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount(\"/gdrive\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MvwLrQbDwdNl"
      },
      "source": [
        "# Install required packages"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xEZLwdqTF0JI",
        "outputId": "290f30f5-db00-479e-c9a3-628c28c91894"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/480.6 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m480.6/480.6 kB\u001b[0m \u001b[31m22.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/433.6 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m433.6/433.6 kB\u001b[0m \u001b[31m32.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m179.3/179.3 kB\u001b[0m \u001b[31m8.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m1.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m99.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m79.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m62.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m2.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m5.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m14.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m8.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m6.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m188.7/188.7 MB\u001b[0m \u001b[31m7.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m61.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "gcsfs 2025.3.0 requires fsspec==2025.3.0, but you have fsspec 2024.9.0 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m460.6/460.6 kB\u001b[0m \u001b[31m39.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m22.4/22.4 MB\u001b[0m \u001b[31m78.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting PyPDF2\n",
            "  Downloading pypdf2-3.0.1-py3-none-any.whl.metadata (6.8 kB)\n",
            "Downloading pypdf2-3.0.1-py3-none-any.whl (232 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m232.6/232.6 kB\u001b[0m \u001b[31m21.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: PyPDF2\n",
            "Successfully installed PyPDF2-3.0.1\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.11/dist-packages (4.55.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from transformers) (3.18.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.34.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.34.3)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (2.0.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (25.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from transformers) (6.0.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (2024.11.6)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from transformers) (2.32.3)\n",
            "Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.21.4)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.6.1)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.11/dist-packages (from transformers) (4.67.1)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.34.0->transformers) (2024.9.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.34.0->transformers) (4.14.1)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.34.0->transformers) (1.1.7)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (2025.8.3)\n",
            "Collecting bitsandbytes\n",
            "  Downloading bitsandbytes-0.46.1-py3-none-manylinux_2_24_x86_64.whl.metadata (10 kB)\n",
            "Requirement already satisfied: torch<3,>=2.2 in /usr/local/lib/python3.11/dist-packages (from bitsandbytes) (2.6.0+cu124)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from bitsandbytes) (2.0.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.2->bitsandbytes) (3.18.0)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.2->bitsandbytes) (4.14.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.2->bitsandbytes) (3.5)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.2->bitsandbytes) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.2->bitsandbytes) (2024.9.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.2->bitsandbytes) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.2->bitsandbytes) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.2->bitsandbytes) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.2->bitsandbytes) (9.1.0.70)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.2->bitsandbytes) (12.4.5.8)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.2->bitsandbytes) (11.2.1.3)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.2->bitsandbytes) (10.3.5.147)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.2->bitsandbytes) (11.6.1.9)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.2->bitsandbytes) (12.3.1.170)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.2->bitsandbytes) (0.6.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.2->bitsandbytes) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.2->bitsandbytes) (12.4.127)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.2->bitsandbytes) (12.4.127)\n",
            "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.2->bitsandbytes) (3.2.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.2->bitsandbytes) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch<3,>=2.2->bitsandbytes) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch<3,>=2.2->bitsandbytes) (3.0.2)\n",
            "Downloading bitsandbytes-0.46.1-py3-none-manylinux_2_24_x86_64.whl (72.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m72.9/72.9 MB\u001b[0m \u001b[31m13.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: bitsandbytes\n",
            "Successfully installed bitsandbytes-0.46.1\n"
          ]
        }
      ],
      "source": [
        "!pip install -qU datasets==3.2.0 optimum==1.24.0\n",
        "!pip install -qU openai==1.61.0 wandb\n",
        "!pip install -qU json-repair==0.29.1\n",
        "!pip install PyPDF2\n",
        "!pip install transformers -U\n",
        "!pip install bitsandbytes -U"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x_539vO0wlSw"
      },
      "source": [
        "# Log in into Hungging Face account and WandB biases"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 315
        },
        "id": "LzhicRAvF7po",
        "outputId": "3cd3521a-e7c5-4b1b-fc83-903686345f23"
      },
      "outputs": [
        {
          "data": {
            "application/javascript": [
              "\n",
              "        window._wandbApiKey = new Promise((resolve, reject) => {\n",
              "            function loadScript(url) {\n",
              "            return new Promise(function(resolve, reject) {\n",
              "                let newScript = document.createElement(\"script\");\n",
              "                newScript.onerror = reject;\n",
              "                newScript.onload = resolve;\n",
              "                document.body.appendChild(newScript);\n",
              "                newScript.src = url;\n",
              "            });\n",
              "            }\n",
              "            loadScript(\"https://cdn.jsdelivr.net/npm/postmate/build/postmate.min.js\").then(() => {\n",
              "            const iframe = document.createElement('iframe')\n",
              "            iframe.style.cssText = \"width:0;height:0;border:none\"\n",
              "            document.body.appendChild(iframe)\n",
              "            const handshake = new Postmate({\n",
              "                container: iframe,\n",
              "                url: 'https://wandb.ai/authorize'\n",
              "            });\n",
              "            const timeout = setTimeout(() => reject(\"Couldn't auto authenticate\"), 5000)\n",
              "            handshake.then(function(child) {\n",
              "                child.on('authorize', data => {\n",
              "                    clearTimeout(timeout)\n",
              "                    resolve(data)\n",
              "                });\n",
              "            });\n",
              "            })\n",
              "        });\n",
              "    "
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Logging into wandb.ai. (Learn how to deploy a W&B server locally: https://wandb.me/wandb-server)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: You can find your API key in your browser here: https://wandb.ai/authorize\n",
            "wandb: Paste an API key from your profile and hit enter:"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " ··········\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m If you're specifying your api key in code, ensure this code is not shared publicly.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Consider setting the WANDB_API_KEY environment variable, or running `wandb login` from the command line.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: No netrc file found, creating one.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mchristeenhallak33\u001b[0m (\u001b[33mchristeenhallak33-coretech-mena\u001b[0m) to \u001b[32mhttps://api.wandb.ai\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[33m⚠️  Warning: 'huggingface-cli login' is deprecated. Use 'hf auth login' instead.\u001b[0m\n",
            "The token has not been saved to the git credentials helper. Pass `add_to_git_credential=True` in this function directly or `--add-to-git-credential` if using via `hf`CLI if you want to set the git credential as well.\n",
            "Token is valid (permission: fineGrained).\n",
            "The token `huggingfaceToken` has been saved to /root/.cache/huggingface/stored_tokens\n",
            "Your token has been saved to /root/.cache/huggingface/token\n",
            "Login successful.\n",
            "The current active token is: `huggingfaceToken`\n"
          ]
        }
      ],
      "source": [
        "from google.colab import userdata\n",
        "import wandb\n",
        "\n",
        "huggingface_key = userdata.get('huggingface')\n",
        "wandb_key = userdata.get('wandb')\n",
        "openai_key = userdata.get('openai')\n",
        "\n",
        "wandb.login()\n",
        "!huggingface-cli login --token {huggingface_key}\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VqF0swKGwu1d"
      },
      "source": [
        "# Import Packages"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "InpPIibLF9Fg"
      },
      "outputs": [],
      "source": [
        "import json\n",
        "import os\n",
        "from os.path import join\n",
        "import random\n",
        "from tqdm.auto import tqdm\n",
        "import requests\n",
        "\n",
        "from pydantic import BaseModel, Field\n",
        "from typing import List, Optional, Literal\n",
        "from datetime import datetime\n",
        "import json_repair\n",
        "\n",
        "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
        "import torch\n",
        "\n",
        "data_dir = '/gdrive/MyDrive/Artificial Intelligence/LLM/Fine Tunning/question_dataset_1000.jsonl'\n",
        "saved_dir = '/gdrive/MyDrive/Artificial Intelligence/LLM/Fine Tunning'\n",
        "gbase_model_id = \"Qwen/Qwen2.5-1.5B-Instruct\"\n",
        "\n",
        "device = \"cuda\"\n",
        "torch_dtype = None\n",
        "\n",
        "def parse_json(text):\n",
        "    try:\n",
        "        return json_repair.loads(text)\n",
        "    except:\n",
        "        return None"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d80k8ttqw2Ts"
      },
      "source": [
        "# Upload local PDF"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 73
        },
        "id": "pS9E86uLF_Ag",
        "outputId": "c584bcbf-0ebe-48ef-9bdf-24fbad8f9c7d"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-8cd64a25-d784-4776-8e7b-5f0d1c382dba\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-8cd64a25-d784-4776-8e7b-5f0d1c382dba\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Saving history of Oman.pdf to history of Oman.pdf\n"
          ]
        }
      ],
      "source": [
        "\n",
        "# Step 1: Upload file from your local device\n",
        "from google.colab import files\n",
        "uploaded = files.upload()  # Opens file picker\n",
        "\n",
        "# Step 2: Extract the file path (assumes single file uploaded)\n",
        "import os\n",
        "\n",
        "pdf_path = next(iter(uploaded))  # Get the uploaded filename\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9fJmAENOw5q8"
      },
      "source": [
        "# Extract Text From the PDF"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gDRjdhZ_GCFw",
        "outputId": "f8225698-de93-4f7e-b74f-c50c39116697"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "التراث والتاريخ العريق في سلطنة عُمان مقدمة سلطنة عُمان، الواقعة في الركن الجنوبي الشرقي من شبه الجزيرة العربية، تُعد واحدة من أقدم الدول التي استوطنتها الحضارات البشرية، ولعبت دورًا مهمًا في تاريخ المنطقة والعالم. بفضل موقعها الجغرافي الفريد، المُطل على ممرات بحرية حيوية، أصبحت مركزًا للتجارة والمالحة منذ آالف السنين. وال يقتصر تميز عُمان على موقعها فقط، بل يمتد إلى تراثها الغني الذي يجمع بين عبق التاريخ وروح األصالة. عُمان عبر العصور عُمان القديمة يعود تاريخ االستيطان البشري في عمان إلى ما قبل أكثر من 10,000 سنة، حيث دلت الحفريات األثرية على وجود حضارات قديمة مثل حضارة \"مجان\"، التي ذكرتها النصوص السومرية وكانت تشتهر بتجارة النحاس والديوريت. العصور اإلسالمية مع بداية القرن السابع الميالدي، دخل اإلسالم إلى عُمان طوعًا، وكان العمانيون من أوائل من اعتنقوا اإلسالم دون قتال. وقد ساهمت عُمان في نشر اإلسالم في شرق أفريقيا والهند وجنوب شرق آسيا عن طريق تجارها وبحّارتها. الدولة اليعربية والنهضة البحرية في القرن السابع عشر، برزت الدولة اليعربية كقوة بحرية عُمانية استطاعت طرد البرتغاليين من سواحل عُمان والخليج، بل وتوسعت حتى وصلت إلى شرق أفريقيا. كانت تلك الفترة ذروة النفوذ البحري العماني، حين أصبحت زنجبار مركزًا تجاريًا وسياسيًا تابعًا للسلطنة. التراث المعماري والحضاري القلع والحصون عُمان تزخر باآلالف من القالع والحصون التي تعكس عبقرية العمارة العُمانية القديمة. من أبرزها: • قلعة نزوى: بُنيت في القرن السابع عشر وتُعد من أبرز رموز الحكم والدفاع في عُمان. • قلعة بهالء: مدرجة ضمن قائمة التراث العالمي لليونسكو، وتُعتبر من أقدم القالع. • حصن جبرين: تحفة معمارية تحتوي على نقوش وزخارف إسالمية بديعة. األسواق التقليدية األسواق القديمة مثل سوق مطرح ال تزال تحتفظ بروح الماضي، حيث تُباع فيه منتجات تقليدية مثل اللبان، الفضيات، النسيج، والعطور العمانية. الحرف اليدوية والفنون التقليدية الحرف التقليدية العديد من الحرف اليدوية ال تزال تُمارس حتى اليوم، مثل: • صناعة الخناجر: رمز الرجولة والهوية الوطنية . • صناعة السفن الخشبية (الغُلل والبغلة): التي اشتهر بها العمانيون منذ قرون. • النسيج والفخار : تنتشر في المناطق الريفية والواحات. الفنون الشعبية عمان غنية بالفنون التقليدية مثل: • الرزحة والعازي : وهما فنّان شعبيان يُؤديان في المناسبات الوطنية. • الهمبل، والميدان: وتُعبر عن مشاعر الفخر واالنتماء. الهوية الثقافية والدينية رغم تطور عُمان واندماجها في العالم المعاصر، إال أنها حافظت على هويتها الثقافية. اللباس التقليدي، اللغة العربية الفصحى واللهجة العمانية، وأسلوب الحياة المحافظ كلها جوانب تُبرز تمسك الشعب العماني بأصالته. الدين اإلسالمي يشكّل جزءًا أساسيًا من حياة العمانيين، والمذهب اإلباضي يُعد المذهب الرئيسي في البالد، وقد ساهم في تشكيل نظام الحكم والقيم االجتماعية القائمة على الشورى والعدل واالعتدال. عُمان والنهضة الحديثة منذ تولي السلطان الراحل قابوس بن سعيد الحكم عام 1970 ، بدأت عُمان نهضة شاملة في جميع المجاالت، لكن دون التخلي عن تراثها. بل تم دمج الحداثة مع األصالة، فشُيدت المباني الحديثة بجانب الحصون القديمة، وتطورت الحياة االقتصادية والتعليمية مع المحافظة على القيم الثقافية. اليوم، في عهد السلطان هيثم بن طارق، تستمر مسيرة التحديث بخطى واثقة، مع تركيز على التوازن بين التنمية المستدامة والحفاظ على اإلرث الحضاري. خاتمة يظل التراث العماني عالمة فارقة في التاريخ العربي واإلسالمي، وتجربة فريدة في التوازن بين الماضي والحاضر. فسلطنة عُمان لم تكن يومًا مجرد نقطة على الخريطة، بل كانت وما تزال وطنًا للتاريخ والهوية، وحاضنة لثقافة أصيلة تستمد قوتها من عمقها الحضاري وروح شعبها األصيل.\n"
          ]
        }
      ],
      "source": [
        "# Step 3: Use your existing function (adjusted to skip URL handling)\n",
        "import PyPDF2\n",
        "\n",
        "def extract_text_from_pdf_local(pdf_path: str) -> str:\n",
        "    \"\"\"Extract text from a local PDF file.\"\"\"\n",
        "    try:\n",
        "        with open(pdf_path, 'rb') as file:\n",
        "            reader = PyPDF2.PdfReader(file)\n",
        "            pages = reader.pages\n",
        "            pdf_text = \" \".join(page.extract_text() or \"\" for page in pages).strip()\n",
        "            return pdf_text\n",
        "    except Exception as e:\n",
        "        return f\"Error reading PDF: {e}\"\n",
        "\n",
        "# Step 4: Extract text from the uploaded PDF\n",
        "pdf_content_local = extract_text_from_pdf_local(pdf_path)\n",
        "\n",
        "pdf_content = ' '.join(pdf_content_local.split())\n",
        "print(pdf_content)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NcA6xlvixDO9"
      },
      "source": [
        "# Define Model Output Schema"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "a3DuMmz_GDs4"
      },
      "outputs": [],
      "source": [
        "from pydantic import BaseModel, Field\n",
        "from typing import List, Dict, Literal\n",
        "\n",
        "\n",
        "# --- Property choices ---\n",
        "DifficultyLevel = Literal[\"Very Easy\", \"Easy\", \"Average\", \"Difficult\"]\n",
        "# BloomTaxonomy = Literal[\"Remember\", \"Apply\", \"Evaluate\"]\n",
        "# LanguageType = Literal[\"Arabic\", \"English\"]\n",
        "# ResponseTime = Literal[\"Short\", \"Medium\", \"Long\"]\n",
        "\n",
        "\n",
        "\n",
        "# --- Properties for a single question ---\n",
        "class QuestionProperties(BaseModel):\n",
        "    difficulty: DifficultyLevel = Field(..., alias=\"Difficulty\")\n",
        "    # bloom_taxonomy: BloomTaxonomy = Field(..., alias=\"Bloom Taxonomy\")\n",
        "    # language: LanguageType = Field(..., alias=\"Language\")\n",
        "    # response_time: ResponseTime = Field(..., alias=\"Response Time\")\n",
        "\n",
        "\n",
        "class Question(BaseModel):\n",
        "    question_text: str = Field(..., description=\"Question text.\")\n",
        "    question_answers: List[str] = Field(..., min_items=2, description=\"List of answer options.\")\n",
        "    correct_answer: str = Field(..., description=\"The correct answer.\")\n",
        "    properties: QuestionProperties = Field(..., description=\"Per-question attributes.\")\n",
        "\n",
        "\n",
        "# --- Full question set schema ---\n",
        "class QuestionSet(BaseModel):\n",
        "    questions: List[Question] = Field(..., description=\"List of MCQs\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eAPBEQezxLfM"
      },
      "source": [
        "# Generate Dynamic Prompt based on parameters like\n",
        "###1.Number of Question\n",
        "###2.Questions Type\n",
        "###3.Number of Choices\n",
        "###4.Difficulty Distribution\n",
        "###5.Language of questoins"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Xxjzx23LGFkQ"
      },
      "outputs": [],
      "source": [
        "def generate_prompt(number_of_questions, question_type, number_of_choices, properties, language):\n",
        "    QUESTION_TYPE_MAP = {\n",
        "        0: \"multiple-choice questions (one correct answer)\",\n",
        "        1: \"multiple-choice questions (multiple correct answers)\",\n",
        "        2: \"true/false questions\",\n",
        "        3: \"essay questions\"\n",
        "    }\n",
        "\n",
        "    property_distributions = {}\n",
        "    question_properties_lines = []\n",
        "    total_questions_assigned = 0\n",
        "    processed_items = []\n",
        "\n",
        "    # First pass: calculate question counts from percentages and collect fixed values\n",
        "    for prop_name, prop_value in properties.items():\n",
        "        if isinstance(prop_value, list) and all(isinstance(item, dict) for item in prop_value):\n",
        "            dist_parts = []\n",
        "            enum_parts = []\n",
        "            for item in prop_value:\n",
        "                for k, v in item.items():\n",
        "                    if isinstance(v, (int, float)):\n",
        "                        count = int((v * number_of_questions) / 100)\n",
        "                        processed_items.append((prop_name, k, v, count))\n",
        "                        total_questions_assigned += count\n",
        "                    else:\n",
        "                        # Handle non-percentage items if necessary, although the current logic assumes percentage for lists of dicts\n",
        "                         pass\n",
        "            if dist_parts:\n",
        "                property_distributions[prop_name] = \", \".join(dist_parts)\n",
        "                question_properties_lines.append(\n",
        "                    f'       \"{prop_name}\": {\" | \".join([k.strip(\"\") for k in enum_parts])}'\n",
        "                )\n",
        "        else:\n",
        "            # Fixed value\n",
        "            property_distributions[prop_name] = str(prop_value)\n",
        "            question_properties_lines.append(f'       \"{prop_name}\": \"{prop_value}\"')\n",
        "\n",
        "\n",
        "    # Adjust remainder to ensure total = number_of_questions for percentage-based distributions\n",
        "    remainder = number_of_questions - total_questions_assigned\n",
        "    if processed_items and remainder > 0:\n",
        "        # Find the item with the largest initial count to add the remainder to\n",
        "        processed_items.sort(key=lambda x: x[3], reverse=True)\n",
        "        prop_name, k, v, count = processed_items[0]\n",
        "        processed_items[0] = (prop_name, k, v, count + remainder)\n",
        "\n",
        "    # Rebuild distribution strings and property lines based on adjusted counts\n",
        "    property_distributions = {}\n",
        "    question_properties_lines = []\n",
        "\n",
        "    for prop_name, prop_value in properties.items():\n",
        "         if isinstance(prop_value, list) and all(isinstance(item, dict) for item in prop_value):\n",
        "            dist_parts = []\n",
        "            enum_parts = []\n",
        "            for item_prop_name, k, v, count in processed_items:\n",
        "                if item_prop_name == prop_name:\n",
        "                    if count > 0:\n",
        "                         dist_parts.append(f'{k} ({count})')\n",
        "                         enum_parts.append(f'\"{k}\"')\n",
        "            if dist_parts:\n",
        "                property_distributions[prop_name] = \", \".join(dist_parts)\n",
        "                question_properties_lines.append(\n",
        "                    f'       \"{prop_name}\": {\" | \".join([k.strip(\"\") for k in enum_parts])}'\n",
        "                )\n",
        "         else:\n",
        "            property_distributions[prop_name] = str(prop_value)\n",
        "            question_properties_lines.append(f'       \"{prop_name}\": \"{prop_value}\"')\n",
        "\n",
        "\n",
        "    # Section for distribution description\n",
        "    distribution_lines = \"\\n\".join([\n",
        "        f\"   - {prop}: {desc}\" for prop, desc in property_distributions.items() if prop != \"extra_properties\"\n",
        "    ])\n",
        "\n",
        "    # Properties block inside each question\n",
        "    question_properties_block = \",\\n\".join(question_properties_lines)\n",
        "    question_type_str = QUESTION_TYPE_MAP.get(question_type, \"questions\")\n",
        "\n",
        "    # Final prompt\n",
        "    prompt = f\"\"\"\n",
        "You are a question generation expert.\n",
        "You will be provided by a PDF content associated with a Pydantic scheme.,\n",
        "generate exactly {number_of_questions} {question_type_str}.\n",
        "Follow these instructions precisely:\n",
        "\n",
        "1. Distribute the {number_of_questions} questions according to these constraints:\n",
        "{distribution_lines}\n",
        "follow the distribution proportions strictly.\n",
        "\n",
        "2. Language of the output must be in {language}\n",
        "\n",
        "⚠️ Do NOT include any explanation, formatting, or text outside the JSON object.\n",
        "⚠️ Ensure the distribution rules are strictly followed. Extract content accurately and comply with the format.\n",
        "\"\"\".strip()\n",
        "\n",
        "    return prompt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4MAI4KS1GIIg"
      },
      "outputs": [],
      "source": [
        "\n",
        "user_prompt = generate_prompt(number_of_questions = 5,question_type=0,number_of_choices=3,language='Arabic',properties={\n",
        "    \"Difficulty\":[{\"Easy\":30,\"Average\":40,\"Difficult\":30}],\n",
        "  })"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_2L-kS6Txuio"
      },
      "source": [
        "# Evaluate the BaseModel(Qwen-1.2b)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fphwBo8uGKwf"
      },
      "outputs": [],
      "source": [
        "import json\n",
        "messages = [\n",
        "    {\"role\": \"system\",\"content\":user_prompt},\n",
        "    {\n",
        "        \"role\": \"user\",\n",
        "        \"content\": \"\\n\".join([\n",
        "            \"## PDF content:\",\n",
        "            pdf_content.strip(),\n",
        "            \"\",\n",
        "\n",
        "            \"## Pydantic Details:\",\n",
        "            json.dumps(\n",
        "                QuestionSet.model_json_schema(), ensure_ascii=False\n",
        "            ),\n",
        "            \"\",\n",
        "\n",
        "            \"## Generated Questions:\",\n",
        "            \"```json\"\n",
        "        ])\n",
        "    }\n",
        "]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 365,
          "referenced_widgets": [
            "681cf59c33e94b50aad9880df1ceb0e4",
            "3b2a162d5fb5464fb8d8f1ffc389fc54",
            "d7d66f004fbc488dbb0bbd48e9e9855d",
            "8ed9d44c42ec48b1b85caaae5b9c9ca6",
            "8966659f010d4bd6b85dd660671ea30e",
            "285ec7ac2e154500a35adff02c6e6a26",
            "0c89244d8d274235a8d41f9b217677f1",
            "0207e0ff80044415a319fb6a526e5257",
            "3ced7c4a24b94e2ca7a20f5f97fba072",
            "d02911307112403bb1f3e8c36962a0b2",
            "ee76ce90fb794454a313723f06648285",
            "e863d07a79954c75a14feeb88a5602e7",
            "8f9a8c0e4984482c8636131bd3821f29",
            "cdb7e805f08d487a9411ec8cd96f1077",
            "8cb24d0833144c7d85eb7a2621cd2bf5",
            "623d728d8a414b638e7c0e3443866043",
            "3d872a0d4d9343918f5ffb0e351f1b19",
            "06dea7c875eb4d3b80a02addbd1b04a7",
            "1d4fd2f1677548a986dbd2eaf70f7a1c",
            "373996cc930c471e857db3ecfdae2d3b",
            "ea305a9a74334474969baa2d6e0143dc",
            "a301ca3ad3164d83af4cab766404313e",
            "392cbd5e7bf54523be6af0908a30ed35",
            "f81de5129d0e495592461f9a7b73c3c7",
            "302a449311fe44f29055ad87e6560cab",
            "c613eff3da0740b5aa1ddd6af781245f",
            "a735dc3dc542468594d2c2b61874fb3e",
            "d915c4494f5043f09137c39ddd3bf577",
            "a7c8abf772c6435ea4a9cb67298cf3bf",
            "a1d79c228c5847cf8d619e97a314f6f8",
            "9c97c66f7b1d42ca9a081e51e18871f3",
            "61806c2ca1984fa1ace449208b05cf1d",
            "048e67b073224f6e81061ef8a4001a5d",
            "57fa89ef1230464d8671e5c084db16dc",
            "89cd4728724c40e5a3d7c83ed2f22bd0",
            "378ff63eb9b1403b9229530bd03ef717",
            "3417f70fb24e460490c0e488f6ed2fd6",
            "35aaa31b5216482d889e747bd5ec18a5",
            "574c8b2ca08642429d76cd277b2bc897",
            "1fa2d5d40122462aa595f17424ad86a6",
            "d53d757dd89e44149fb62588adb8089d",
            "24ad6c14e39549488c66caeb065daa36",
            "65852b078afc4329bdbcc4370945439b",
            "5eb6384e0ba548cfba56101c6e9e8051",
            "63bf153b59e84582b25a94a5bd3ae212",
            "24d8e22a526342b8b56fec35bbab7fb7",
            "6561c47d38f5434fa049ce6eac9b1d33",
            "bd6b4bbcc2514189a50a6aa6d1d4eaaf",
            "663e22b5408340179ffa7cd68a7de189",
            "0f30048de046486c9914a61bd67c9c46",
            "12d36f867f944d8c8709eceaa746414f",
            "4671e77c75594b84ab004aa91702db84",
            "4844edefadd04c11a661a817526d03d0",
            "a20df8b260364ec19ce6af290c5420bd",
            "b299fc614149484ba2579cd3337a5f43",
            "0a30d07d95e3456c9fbf886ed7361d3b",
            "2382bd9d01b348c5bfc7369eb1b6e1ac",
            "f44677a525eb454f8874a17b9aa629a8",
            "609aebd8977f4287b67d81374ea086e6",
            "0d4040bd0da749feb8353857b85272ea",
            "9f10c61a02d7401e84766c5f7e2da85a",
            "fc41268f4ffa49d182dfba7e11314b38",
            "d12d5aff61324f54a8e602c79d8a8475",
            "04dffa75c6264eebb5d19e2954292f82",
            "9484bf0a88cd4450b44fbf740e02b60a",
            "0ff4e515e62f4543a58142742c87abac",
            "0f23dc4c5e6047faa40ad60c965c9cb8",
            "6d7dc275e29344f7a0fcf4242e98f681",
            "65bb252631bb4b1e8ffa4040d5d75c13",
            "355590ce4bf6459b89348660ba3fc211",
            "768099561a7d4abf97fa36c7c2030543",
            "62cca5f2f3b1425eba3161ff3cdd1721",
            "4eaf0eb669ec4a23a24bfe79c8537e2e",
            "d794c2a04c474e91bb282b9e71a185ac",
            "474b3e2720e549fb995b0e824880c5a0",
            "1f231cf97cc249dea2278abb86d0b155",
            "d9b03d77660c4165b24ef8e603fbb8b3"
          ]
        },
        "id": "PDDw4FvGGKzP",
        "outputId": "31fbdff5-de57-44d3-f2f0-a5776b94e7ed"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "681cf59c33e94b50aad9880df1ceb0e4",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "config.json:   0%|          | 0.00/660 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "e863d07a79954c75a14feeb88a5602e7",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "model.safetensors:   0%|          | 0.00/3.09G [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "392cbd5e7bf54523be6af0908a30ed35",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "generation_config.json:   0%|          | 0.00/242 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "57fa89ef1230464d8671e5c084db16dc",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "tokenizer_config.json: 0.00B [00:00, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "63bf153b59e84582b25a94a5bd3ae212",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "vocab.json: 0.00B [00:00, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "0a30d07d95e3456c9fbf886ed7361d3b",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "merges.txt: 0.00B [00:00, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "0f23dc4c5e6047faa40ad60c965c9cb8",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "tokenizer.json: 0.00B [00:00, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "torch_dtype = None\n",
        "base_model = AutoModelForCausalLM.from_pretrained(\n",
        "    gbase_model_id,\n",
        "    device_map = \"auto\",\n",
        "    torch_dtype = torch_dtype,\n",
        ")\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(gbase_model_id)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j5Byvox8GK2A",
        "outputId": "7d6f3ee8-9afa-4b9b-e5f5-ff7d513fc69d"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "The attention mask is not set and cannot be inferred from input because pad token is same as eos token. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "[{'question_text': 'عُمان تُعد واحدة من أقدم الدول التي استوطنتها الحضارات البشرية، كيف يمكن أن نحدد هذا التاريخ؟',\n",
              "  'question_answers': ['منذ حوالي 10,000 سنة',\n",
              "   'منذ حوالي 8,000 سنة',\n",
              "   'منذ حوالي 6,000 سنة',\n",
              "   'منذ حوالي 4,000 سنة'],\n",
              "  'correct_answer': 'منذ حوالي 10,000 سنة',\n",
              "  'properties': {}},\n",
              " {'question_text': 'عُمان تُعتبر مركزًا للتجارة والمالحة منذ آلف السنين، كيف يمكن أن نفهم هذا التاريخ؟',\n",
              "  'question_answers': ['منذ القرن الأول الميلادي',\n",
              "   'منذ القرن الثاني الميلادي',\n",
              "   'منذ القرن الثالث الميلادي',\n",
              "   'منذ القرن الرابع الميلادي'],\n",
              "  'correct_answer': 'منذ القرن الرابع الميلادي',\n",
              "  'properties': {}},\n",
              " {'question_text': 'عُمان عبر العصور عُمان القديمة، كيف يمكن أن نفهم هذا التاريخ؟',\n",
              "  'question_answers': ['عبر العصور الإسلامية',\n",
              "   'عبر العصور الأسلامية',\n",
              "   'عبر العصور الإسلامية واليهودية',\n",
              "   'عبر العصور الإسلامية واليهودية والبوذية'],\n",
              "  'correct_answer': 'عبر العصور الإسلامية',\n",
              "  'properties': {}},\n",
              " {'question_text': 'عُمان تُعتبر مركزًا تجاريًا وسياسيًا تابعًا للسلطنة، كيف يمكن أن نفهم هذا التاريخ؟',\n",
              "  'question_answers': ['منذ القرن السابع عشر',\n",
              "   'منذ القرن الثامن عشر',\n",
              "   'منذ القرن التاسع عشر',\n",
              "   'منذ القرن العاشر'],\n",
              "  'correct_answer': 'منذ القرن السابع عشر',\n",
              "  'properties': {}},\n",
              " {'question_text': 'عُمان تُعتبر مركزًا تجاريًا وسياسيًا تابعًا للسلطنة، كيف يمكن أن نفهم هذا التاريخ؟',\n",
              "  'question_answers': ['منذ القرن السابع عشر',\n",
              "   'منذ القرن الثامن عشر',\n",
              "   'منذ القرن التاسع عشر',\n",
              "   'منذ القرن العاشر'],\n",
              "  'correct_answer': 'منذ القرن السابع عشر',\n",
              "  'properties': {}}]"
            ]
          },
          "execution_count": 14,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "text = tokenizer.apply_chat_template(\n",
        "    messages,\n",
        "    tokenize=False,\n",
        "    add_generation_prompt=True\n",
        ")\n",
        "\n",
        "model_inputs = tokenizer([text], return_tensors=\"pt\").to(device)\n",
        "\n",
        "generated_ids = base_model.generate(\n",
        "    model_inputs.input_ids,\n",
        "    max_new_tokens=1024,\n",
        "    do_sample=False, top_k=None, temperature=None, top_p=None,\n",
        ")\n",
        "\n",
        "generated_ids = [\n",
        "    output_ids[len(input_ids):]\n",
        "    for input_ids, output_ids in zip(model_inputs.input_ids, generated_ids)\n",
        "]\n",
        "\n",
        "response = tokenizer.batch_decode(generated_ids, skip_special_tokens=True)[0]\n",
        "json.loads(response)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8X9B5kM_kU-K"
      },
      "source": [
        "# Fine Tunning Qwen Model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xPBWE9tDGgB4"
      },
      "source": [
        "## Format FineTunning Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EjSjs7dRGK4P",
        "outputId": "1068365c-86d4-41d5-96a3-1d331cab3923"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "1175"
            ]
          },
          "execution_count": 13,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "\n",
        "sft_data_path = data_dir\n",
        "llm_finetunning_data = []\n",
        "\n",
        "system_message = \"\\n\".join([\n",
        "    \"You are a question generation expert\",\n",
        "    \"You will be provided by a PDF content associated with a Pydantic scheme.,\",\n",
        "    \"Follow the provided `Task` by the user and the `Output Scheme` to generate the `Output JSON`.\",\n",
        "    \"Do not generate any introduction or conclusion.\"\n",
        "])\n",
        "\n",
        "for line in open(sft_data_path):\n",
        "    if line.strip() == \"\":\n",
        "        continue\n",
        "\n",
        "    rec = json.loads(line.strip())\n",
        "\n",
        "    llm_finetunning_data.append({\n",
        "        \"system\": system_message,\n",
        "        \"instruction\": \"\\n\".join([\n",
        "            \"# PDF CONTENT:\",\n",
        "            rec[\"input\"],\n",
        "\n",
        "            \"# Task:\",\n",
        "            rec[\"instruction\"],\n",
        "\n",
        "            \"# Output Scheme:\",\n",
        "            json.dumps( QuestionSet.model_json_schema(), ensure_ascii=False ),\n",
        "            \"\",\n",
        "\n",
        "            \"# Output JSON:\",\n",
        "            \"```json\"\n",
        "\n",
        "        ]),\n",
        "        \"input\": \"\",\n",
        "        \"output\": \"\\n\".join([\n",
        "            \"```json\",\n",
        "            json.dumps(rec[\"output\"], ensure_ascii=False, default=str),\n",
        "            \"```\"\n",
        "        ]),\n",
        "        \"history\": []\n",
        "    })\n",
        "\n",
        "random.Random(101).shuffle(llm_finetunning_data)\n",
        "len(llm_finetunning_data)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5C5jHsQtkySp"
      },
      "source": [
        "## Splitting Dataset into Train and Eval Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kAxSuOcpMMop"
      },
      "outputs": [],
      "source": [
        "train_sample_sz = 1000\n",
        "\n",
        "train_ds = llm_finetunning_data[:train_sample_sz]\n",
        "eval_ds = llm_finetunning_data[train_sample_sz:]\n",
        "\n",
        "os.makedirs(join(saved_dir, \"datasets\", \"llamafactory-finetune-data\"), exist_ok=True)\n",
        "\n",
        "with open(join(saved_dir, \"datasets\", \"llamafactory-finetune-data\", \"train.json\"), \"w\") as dest:\n",
        "    json.dump(train_ds, dest, ensure_ascii=False, default=str)\n",
        "\n",
        "with open(join(saved_dir, \"datasets\", \"llamafactory-finetune-data\", \"val.json\"), \"w\", encoding=\"utf8\") as dest:\n",
        "    json.dump(eval_ds, dest, ensure_ascii=False, default=str)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HrLL1nrdk3c_"
      },
      "source": [
        "## Clonning LLaMA Factory"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "99T54g9H21Z0",
        "outputId": "4b72078b-6249-4c4f-ab30-6b8a6deb6f55"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "fatal: destination path 'LLaMA-Factory' already exists and is not an empty directory.\n"
          ]
        }
      ],
      "source": [
        "!git clone \"https://github.com/hiyouga/LLaMA-Factory.git\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 157
        },
        "id": "FoKMZ44L5abp",
        "outputId": "712fc688-357a-474c-eaaf-e8d4949c00c8"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'\\n        \"news_finetune_train\": {\\n            \"file_name\": \"/gdrive/MyDrive/Artificial Intelligence/LLM/Fine Tunning/datasets/llamafactory-finetune-data/train.json\",\\n            \"columns\": {\\n                \"prompt\": \"instruction\",\\n                \"query\": \"input\",\\n                \"response\": \"output\",\\n                \"system\": \"system\",\\n                \"history\": \"history\"\\n            }\\n        },\\n        \"news_finetune_val\": {\\n            \"file_name\": \"/gdrive/MyDrive/Artificial Intelligence/LLM/Fine Tunning/datasets/llamafactory-finetune-data/val.json\",\\n            \"columns\": {\\n                \"prompt\": \"instruction\",\\n                \"query\": \"input\",\\n                \"response\": \"output\",\\n                \"system\": \"system\",\\n                \"history\": \"history\"\\n            }\\n        }\\n'"
            ]
          },
          "execution_count": 18,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# # Configure LLaMA-Factory for the new datasets\n",
        "\n",
        "# # update /content/LLaMA-Factory/data/dataset_info.json and append\n",
        "'''\n",
        "        \"news_finetune_train\": {\n",
        "            \"file_name\": \"/gdrive/MyDrive/Artificial Intelligence/LLM/Fine Tunning/datasets/llamafactory-finetune-data/train.json\",\n",
        "            \"columns\": {\n",
        "                \"prompt\": \"instruction\",\n",
        "                \"query\": \"input\",\n",
        "                \"response\": \"output\",\n",
        "                \"system\": \"system\",\n",
        "                \"history\": \"history\"\n",
        "            }\n",
        "        },\n",
        "        \"news_finetune_val\": {\n",
        "            \"file_name\": \"/gdrive/MyDrive/Artificial Intelligence/LLM/Fine Tunning/datasets/llamafactory-finetune-data/val.json\",\n",
        "            \"columns\": {\n",
        "                \"prompt\": \"instruction\",\n",
        "                \"query\": \"input\",\n",
        "                \"response\": \"output\",\n",
        "                \"system\": \"system\",\n",
        "                \"history\": \"history\"\n",
        "            }\n",
        "        }\n",
        "'''\n",
        "\n",
        "# https://wandb.ai/mr-bakrianoo/llamafactory/runs/apwbkni9\n",
        "# https://wandb.ai/mr-bakrianoo/llamafactory/runs/c5tf0q90"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_fkB0ncLk-Uy"
      },
      "source": [
        "## Configuration for Llama factory fine tunning"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EOct6hy6_mmJ",
        "outputId": "671e9714-e6e7-4b97-e60a-6a0ac63f343a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Overwriting /content/LLaMA-Factory/examples/train_lora/news_finetune.yaml\n"
          ]
        }
      ],
      "source": [
        "%%writefile /content/LLaMA-Factory/examples/train_lora/news_finetune.yaml\n",
        "\n",
        "### model\n",
        "model_name_or_path: Qwen/Qwen2.5-1.5B-Instruct\n",
        "trust_remote_code: true\n",
        "\n",
        "### method\n",
        "stage: sft\n",
        "do_train: true\n",
        "finetuning_type: lora\n",
        "lora_rank: 64\n",
        "lora_target: all\n",
        "\n",
        "### dataset\n",
        "dataset: news_finetune_train\n",
        "eval_dataset: news_finetune_val\n",
        "template: qwen\n",
        "cutoff_len: 3500\n",
        "# max_samples: 50\n",
        "overwrite_cache: true\n",
        "preprocessing_num_workers: 16\n",
        "\n",
        "### output\n",
        "resume_from_checkpoint: /gdrive/MyDrive/Artificial Intelligence/LLM/Fine Tunning/Qwen_models/checkpoint-300\n",
        "output_dir: /gdrive/MyDrive/Artificial Intelligence/LLM/Fine Tunning/Qwen_models/\n",
        "logging_steps: 10\n",
        "save_strategy: steps\n",
        "save_steps: 50\n",
        "plot_loss: true\n",
        "overwrite_output_dir: true\n",
        "\n",
        "### train\n",
        "per_device_train_batch_size: 1\n",
        "gradient_accumulation_steps: 4\n",
        "learning_rate: 1.0e-4\n",
        "num_train_epochs: 3.0\n",
        "lr_scheduler_type: cosine\n",
        "warmup_ratio: 0.1\n",
        "bf16: true\n",
        "ddp_timeout: 180000000\n",
        "\n",
        "### eval\n",
        "# val_size: 0.1\n",
        "per_device_eval_batch_size: 1\n",
        "eval_strategy: steps\n",
        "eval_steps: 50\n",
        "\n",
        "report_to: wandb\n",
        "run_name: questions_generations_Qwen\n",
        "\n",
        "push_to_hub: true\n",
        "export_hub_model_id: \"Christeen33/questions_generations_Qwen\"\n",
        "hub_private_repo: true\n",
        "hub_strategy: checkpoint\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fOgzWeEUWyhF",
        "outputId": "92d0e1eb-1ba0-4204-bfe7-00d6a75dca3d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "fatal: destination path 'LLaMA-Factory' already exists and is not an empty directory.\n",
            "/content/LLaMA-Factory\n",
            "/bin/bash: line 1: llamafactory-cli: command not found\n"
          ]
        }
      ],
      "source": [
        "# # STEP 1: Clone the repo\n",
        "# !git clone https://github.com/hiyouga/LLaMA-Factory.git\n",
        "\n",
        "# STEP 2: Change directory\n",
        "%cd LLaMA-Factory\n",
        "\n",
        "# STEP 3: Install in editable mode\n",
        "!pip install -e .\n",
        "\n",
        "# Force restart the runtime (only works in Colab)\n",
        "import os\n",
        "os.kill(os.getpid(), 9)  # This will crash the runtime and force a restart\n",
        "\n",
        "# After restarting, run only the training command in a new cell:\n",
        "# !llamafactory-cli train examples/train_lora/news_finetune.yaml"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Idokr5R4l1sr"
      },
      "source": [
        "## Tranning and saving with checkpoints"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dfdNZCx8XIrF"
      },
      "outputs": [],
      "source": [
        "%cd /content/LLaMA-Factory"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zXjLs29PZ9kX"
      },
      "outputs": [],
      "source": [
        "\n",
        "# STEP 4: Run training using the example config\n",
        "!llamafactory-cli train examples/train_lora/news_finetune.yaml\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mZazzvuhkNGy"
      },
      "source": [
        "# Testing Model After Fine Tunning"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "noqMqp7lkBAA"
      },
      "outputs": [],
      "source": [
        "torch_dtype = None\n",
        "base_model = AutoModelForCausalLM.from_pretrained(\n",
        "    gbase_model_id,\n",
        "    device_map = \"auto\",\n",
        "    torch_dtype = torch_dtype,\n",
        ")\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(gbase_model_id)\n",
        "\n",
        "finetuned_model_id = \"/gdrive/MyDrive/Artificial Intelligence/LLM/Fine Tunning/Qwen_models/checkpoint-750\"\n",
        "base_model.load_adapter(finetuned_model_id)\n",
        "\n",
        "text = tokenizer.apply_chat_template(\n",
        "    messages,\n",
        "    tokenize=False,\n",
        "    add_generation_prompt=True\n",
        ")\n",
        "\n",
        "model_inputs = tokenizer([text], return_tensors=\"pt\").to(device)\n",
        "\n",
        "generated_ids = base_model.generate(\n",
        "    model_inputs.input_ids,\n",
        "    max_new_tokens=1024,\n",
        "    do_sample=False, top_k=None, temperature=None, top_p=None,\n",
        ")\n",
        "\n",
        "generated_ids = [\n",
        "    output_ids[len(input_ids):]\n",
        "    for input_ids, output_ids in zip(model_inputs.input_ids, generated_ids)\n",
        "]\n",
        "\n",
        "response = tokenizer.batch_decode(generated_ids, skip_special_tokens=True)[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 279
        },
        "id": "ek9wJucGtROE",
        "outputId": "1f7ee3dd-f126-4a0d-e2fa-f87203e75e4d"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'```json\\n\"{\\\\n    \\\\\"questions\\\\\": [\\\\n        {\\\\n            \\\\\"question_text\\\\\": \\\\\"ما هي الدولة التي تقع في الركن الجنوبي الشرقي من شبه الجزيرة العربية؟\\\\\",\\\\n            \\\\\"question_answers\\\\\": [\\\\n                \\\\\"سلطنة عُمان\\\\\",\\\\n                \\\\\"دولة الإمارات\\\\\",\\\\n                \\\\\"البحرين\\\\\",\\\\n                \\\\\"قطر\\\\\"\\\\n            ],\\\\n            \\\\\"correct_answer\\\\\": \\\\\"سلطنة عُمان\\\\\",\\\\n            \\\\\"properties\\\\\": {\\\\n                \\\\\"Difficulty\\\\\": \\\\\"Easy\\\\\",\\\\n                \\\\\"Language\\\\\": \\\\\"Arabic\\\\\"\\\\n            }\\\\n        },\\\\n        {\\\\n            \\\\\"question_text\\\\\": \\\\\"متى يعود تاريخ الاستيطان البشري في عُمان إلى؟\\\\\",\\\\n            \\\\\"question_answers\\\\\": [\\\\n                \\\\\"آلف سنة\\\\\",\\\\n                \\\\\"4000 سنة atrás\\\\\",\\\\n                \\\\\"10,000 سنة atrás\\\\\",\\\\n                \\\\\"6000 سنة atrás\\\\\"\\\\n            ],\\\\n            \\\\\"correct_answer\\\\\": \\\\\"10,000 سنة atrás\\\\\",\\\\n            \\\\\"properties\\\\\": {\\\\n                \\\\\"Difficulty\\\\\": \\\\\"Easy\\\\\",\\\\n                \\\\\"Language\\\\\": \\\\\"Arabic\\\\\"\\\\n            }\\\\n        },\\\\n        {\\\\n            \\\\\"question_text\\\\\": \\\\\"ما هو أحد أشهر القالع في عُمان؟\\\\\",\\\\n            \\\\\"question_answers\\\\\": [\\\\n                \\\\\"قلعة بهالء\\\\\",\\\\n                \\\\\"قلعة نزوى\\\\\",\\\\n                \\\\\"حصن جبرين\\\\\",\\\\n                \\\\\"قصبة المنصور\\\\\"\\\\n            ],\\\\n            \\\\\"correct_answer\\\\\": \\\\\"قلعة نزوى\\\\\",\\\\n            \\\\\"properties\\\\\": {\\\\n                \\\\\"Difficulty\\\\\": \\\\\"Average\\\\\",\\\\n                \\\\\"Language\\\\\": \\\\\"Arabic\\\\\"\\\\n            }\\\\n        },\\\\n        {\\\\n            \\\\\"question_text\\\\\": \\\\\"كيف ساهمت عُمان في نشر اإلسالم في العالم؟\\\\\",\\\\n            \\\\\"question_answers\\\\\": [\\\\n                \\\\\"عن طريق التجارة فقط\\\\\",\\\\n                \\\\\"من خلال الحروب\\\\\",\\\\n                \\\\\"عن طريق التجارب العلمية\\\\\",\\\\n                \\\\\"عبر تجاربهم وبحّارتهم\\\\\"\\\\n            ],\\\\n            \\\\\"correct_answer\\\\\": \\\\\"عبر تجاربهم وبحّارتهم\\\\\",\\\\n            \\\\\"properties\\\\\": {\\\\n                \\\\\"Difficulty\\\\\": \\\\\"Average\\\\\",\\\\n                \\\\\"Language\\\\\": \\\\\"Arabic\\\\\"\\\\n            }\\\\n        },\\\\n        {\\\\n            \\\\\"question_text\\\\\": \\\\\"ما هي الفترة التي مر فيها عُمان ذروة نفوذها البحري؟\\\\\",\\\\n            \\\\\"question_answers\\\\\": [\\\\n                \\\\\"القرن الخامس عشر\\\\\",\\\\n                \\\\\"القرن السابع عشر\\\\\",\\\\n                \\\\\"القرن الثامن عشر\\\\\",\\\\n                \\\\\"القرن التاسع عشر\\\\\"\\\\n            ],\\\\n            \\\\\"correct_answer\\\\\": \\\\\"القرن السابع عشر\\\\\",\\\\n            \\\\\"properties\\\\\": {\\\\n                \\\\\"Difficulty\\\\\": \\\\\"Average\\\\\",\\\\n                \\\\\"Language\\\\\": \\\\\"Arabic\\\\\"\\\\n            }\\\\n        }\\\\n    ]\\\\n}\"\\n```'"
            ]
          },
          "execution_count": 32,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "response"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hykJlL8atwnl"
      },
      "outputs": [],
      "source": [
        "cleaned = response.strip()\n",
        "\n",
        "# Optional: If the model sometimes wraps JSON in markdown (```json ... ```), strip that\n",
        "if cleaned.startswith(\"```json\"):\n",
        "    cleaned = cleaned.strip(\"```json\").strip(\"`\").strip()\n",
        "\n",
        "# Attempt to parse\n",
        "result = json.loads(cleaned)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 123
        },
        "id": "hKhdu9djuNMj",
        "outputId": "6b314b79-d038-45af-d5db-ae2761ad8119"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'{\\n    \"questions\": [\\n        {\\n            \"question_text\": \"ما هي الدولة التي تقع في الركن الجنوبي الشرقي من شبه الجزيرة العربية؟\",\\n            \"question_answers\": [\\n                \"سلطنة عُمان\",\\n                \"دولة الإمارات\",\\n                \"البحرين\",\\n                \"قطر\"\\n            ],\\n            \"correct_answer\": \"سلطنة عُمان\",\\n            \"properties\": {\\n                \"Difficulty\": \"Easy\",\\n                \"Language\": \"Arabic\"\\n            }\\n        },\\n        {\\n            \"question_text\": \"متى يعود تاريخ الاستيطان البشري في عُمان إلى؟\",\\n            \"question_answers\": [\\n                \"آلف سنة\",\\n                \"4000 سنة atrás\",\\n                \"10,000 سنة atrás\",\\n                \"6000 سنة atrás\"\\n            ],\\n            \"correct_answer\": \"10,000 سنة atrás\",\\n            \"properties\": {\\n                \"Difficulty\": \"Easy\",\\n                \"Language\": \"Arabic\"\\n            }\\n        },\\n        {\\n            \"question_text\": \"ما هو أحد أشهر القالع في عُمان؟\",\\n            \"question_answers\": [\\n                \"قلعة بهالء\",\\n                \"قلعة نزوى\",\\n                \"حصن جبرين\",\\n                \"قصبة المنصور\"\\n            ],\\n            \"correct_answer\": \"قلعة نزوى\",\\n            \"properties\": {\\n                \"Difficulty\": \"Average\",\\n                \"Language\": \"Arabic\"\\n            }\\n        },\\n        {\\n            \"question_text\": \"كيف ساهمت عُمان في نشر اإلسالم في العالم؟\",\\n            \"question_answers\": [\\n                \"عن طريق التجارة فقط\",\\n                \"من خلال الحروب\",\\n                \"عن طريق التجارب العلمية\",\\n                \"عبر تجاربهم وبحّارتهم\"\\n            ],\\n            \"correct_answer\": \"عبر تجاربهم وبحّارتهم\",\\n            \"properties\": {\\n                \"Difficulty\": \"Average\",\\n                \"Language\": \"Arabic\"\\n            }\\n        },\\n        {\\n            \"question_text\": \"ما هي الفترة التي مر فيها عُمان ذروة نفوذها البحري؟\",\\n            \"question_answers\": [\\n                \"القرن الخامس عشر\",\\n                \"القرن السابع عشر\",\\n                \"القرن الثامن عشر\",\\n                \"القرن التاسع عشر\"\\n            ],\\n            \"correct_answer\": \"القرن السابع عشر\",\\n            \"properties\": {\\n                \"Difficulty\": \"Average\",\\n                \"Language\": \"Arabic\"\\n            }\\n        }\\n    ]\\n}'"
            ]
          },
          "execution_count": 36,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "result"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nX7iy7TCvB0e",
        "outputId": "85596221-c412-4910-d707-62354fe25205"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'questions': [{'question_text': 'ما هي الدولة التي تقع في الركن الجنوبي الشرقي من شبه الجزيرة العربية؟',\n",
              "   'question_answers': ['سلطنة عُمان', 'دولة الإمارات', 'البحرين', 'قطر'],\n",
              "   'correct_answer': 'سلطنة عُمان',\n",
              "   'properties': {'Difficulty': 'Easy', 'Language': 'Arabic'}},\n",
              "  {'question_text': 'متى يعود تاريخ الاستيطان البشري في عُمان إلى؟',\n",
              "   'question_answers': ['آلف سنة',\n",
              "    '4000 سنة atrás',\n",
              "    '10,000 سنة atrás',\n",
              "    '6000 سنة atrás'],\n",
              "   'correct_answer': '10,000 سنة atrás',\n",
              "   'properties': {'Difficulty': 'Easy', 'Language': 'Arabic'}},\n",
              "  {'question_text': 'ما هو أحد أشهر القالع في عُمان؟',\n",
              "   'question_answers': ['قلعة بهالء',\n",
              "    'قلعة نزوى',\n",
              "    'حصن جبرين',\n",
              "    'قصبة المنصور'],\n",
              "   'correct_answer': 'قلعة نزوى',\n",
              "   'properties': {'Difficulty': 'Average', 'Language': 'Arabic'}},\n",
              "  {'question_text': 'كيف ساهمت عُمان في نشر اإلسالم في العالم؟',\n",
              "   'question_answers': ['عن طريق التجارة فقط',\n",
              "    'من خلال الحروب',\n",
              "    'عن طريق التجارب العلمية',\n",
              "    'عبر تجاربهم وبحّارتهم'],\n",
              "   'correct_answer': 'عبر تجاربهم وبحّارتهم',\n",
              "   'properties': {'Difficulty': 'Average', 'Language': 'Arabic'}},\n",
              "  {'question_text': 'ما هي الفترة التي مر فيها عُمان ذروة نفوذها البحري؟',\n",
              "   'question_answers': ['القرن الخامس عشر',\n",
              "    'القرن السابع عشر',\n",
              "    'القرن الثامن عشر',\n",
              "    'القرن التاسع عشر'],\n",
              "   'correct_answer': 'القرن السابع عشر',\n",
              "   'properties': {'Difficulty': 'Average', 'Language': 'Arabic'}}]}"
            ]
          },
          "execution_count": 37,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "json.loads(result)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KeggqxA2vEkA"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}